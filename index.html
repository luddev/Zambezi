<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Zambezi</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Zambezi</h1>
        <p class="view"><a href="http://github.com/nasadi/Zambezi">View the Project on GitHub
            <small>nasadi/Zambezi</small></a></p>
      </header>
      <section>

<h2>
An open-source search engine that performs in-memory indexing
and retrieval using a multi-stage learning-to-rank architecture.
</h2>

<p>Components include:</p>

<ul>

<li>Indexer: An incremental indexing algorithm that constructs
block-compressed positional and non-positional inverted indexes
in the main memory, thereby enabling fast indexing and retrieval.
The indexer is also capable of building Bloom filter chains
to be used with our BW<font size=1>AND</font> algorithm for faster top-<i>k</i> retrieval.
</li>

<li>Top-<i>k</i> Retrieval: As the first stage of retrieval,
Zambezi retrieves top <i>k</i> documents that are most relevant to
an input query. Zambezi uses W<font size=1>AND</font> to retrieve
documents ranked using BM25. For microblog documents, Zambezi utilizes
the BW<font size=1>AND</font> algorithm to retrieve documents
using time and a simplified BM25 scoring function, which is an order
of magnitude faster than W<font size=1>AND</font>.
</li>

<li>Feature Extraction: Once the top-<i>k</i> documents are
retrieved, Zambezi computes feature values for each candidate document
before passing the feature vectors to the final, re-ranking stage.
Features can be query dependent (e.g., term and phrase queries),
or query independent, given as a table.
</li>

<li>Document Re-Ranking: In the final stage of retrieval,
candidates are re-ranked using a machine-learned model.
Currently Zambezi supports Lambda-MART models and evaluates
instances using the VP<font size=1>RED</font> implementation
of trees.

</ul>

<a id="Indexing"></a>
<p class="lead" style="padding-top: 60px">Indexing</p>

<p>
The input to the index is a set of (gzipped or raw) text files.
Each line in an input file contains one document in the following format:
</p>

<pre>
  &lt;document_id: integer&gt; \t &lt;document: text&gt;.
</pre>

<p>Please note that, you must perform necessary preprocessing (e.g.,
parsing, stopping, stemming) prior to using the indexer, as the
indexer is only able to read parsed documents and does not perform
any sort of stopping or stemming. We have provided parsers for
ClueWeb09, Gov2, and Tweets2011 collections under <code>util/</code>.
Note that, building these classes requires
<a href="http://lintool.github.com/Cloud9">Cloud<sup>9</sup></a>,
<a href="http://lintool.github.com/Ivory">Ivory</a>,
and <a href="http://twittertools.cc/">twitter-tools</a>.

</p>

<p>
To run the indexer:
</p>

<pre>
out/driver/indexer -index &lt;output-index-root-path&gt; \
                   [-tf | -positional] [-reverse] [-vectors] \
                   [-bloom -r &lt;bits-per-element&gt; -k &lt;number-of-hash-functions&gt;] \
                   -mb &lt;maximum-buffer-length-in-number-of-blocks&gt; \
                   -input &lt;input-paths&gt;
</pre>

<p>
<ul>
  <li><code>-index</code> is the root path to where the index should be stored</li>
  <li><code>-tf | -positional</code> determines whether to augment the index structure with
    term frequencies, or term frequencies and term positionsl.</li>
  <li><code>-reverse</code> indicates that postings will be stored in
    reverse order, such that the last posting inserted into the index will be read first.</li>
  <li>With <code>-vectors</code>, the indexer accumulates document vectors which can be used
    in feature extraction.</li>
  <li>With <code>-bloom</code>, the indexer constructs Bloom filter chains to be used with the
    BW<font size=1>AND</font> algorithm in top-<i>k</i> retrieval. <code>-r</code> and
    <code>-k</code> are the number of bits per element and the number of hash functions,
    respectively.</li>
  <li><code>-mb</code> is the maximum buffer length (in blocks of 128 integers) in buffer maps.
    Larger values translate into more contiguous inverted lists. Experimental evaluation
    shows that setting <code>-mb</code> to 32 yields retrieval speed that is indistinguishable
    from a fully contiguous index.</li>
  <li><code>-input</code> is a list of (gzipped) input files. Note that, this argument
    must appear last.</li>
</ul>
</p>

<a id="Retrieval"></a>
<p class="lead" style="padding-top: 60px">Retrieval</p>

<p>
To perform retrieval:
</p>

<pre>
out/driver/retrieval -index &lt;index-root-path&gt; \
                     -query &lt;query-path&gt; \
                     -algorithm &lt;SvS|WAND|MBWAND|BWAND_OR|BWAND_AND&gt; \
                     [-features &lt;feature-path&gt;] \
                     [-model &lt;tree-ensemble-path&gt;] \
                     [-hits &lt;hits&gt;] \
                     [-output &lt;output-path&gt;]
</pre>

<p>
<ul>
  <li><code>-index</code> is the root path to where the index is stored</li>
  <li><code>-query</code> is the path to a query file</li>
  <li><code>-algorithm</code> is the algorithm used in the top-<i>k</i> retrieval
    stage. These algorithms are as follows:</li>
  <ul>
    <li>SvS: The Small vs. Small algorithm for conjunctive retrieval.</li>
    <li>WAND: The W<font size=1>AND</font> algorithm, using Okapi-BM25 scoring function.</li>
    <li>MBWAND: The W<font size=1>AND</font> algorithm, using IDF scoring function</li>
    <li>BWAND_OR: The BW<font size=1>AND</font> algorithm in disjunctive mode</li>
    <li>BWAND_AND: The BW<font size=1>AND</font> algorithm in conjunctive mode</li>
  </ul>
  <li>With <code>-features</code>, the driver will forward the candidate documents
    to the feature extraction stage and compute feature values</li>
  <li><code>-model</code>, is the path to a file that contains a Lambda-MART model.
    If a model is provided and <code>-features</code> is included,
    candidate documents are re-ranked using the given model.
    For formatting details of the tree model file,
    please see our open-source tree implementation package,
    <a href="http://nasadi.github.com/OptTrees">OptTrees</a>.</li>
  <li><code>-hits</code> is the number of candidate documents to retrieve (i.e., <i>k</i>).</li>
  <li>If <code>-output</code> is included, the output is stored at &lt;output-path&gt;</li>
</ul>

In all cases, per-query latency is printed on stdout.
</p>

<p>
Also note that, queries should be in the following format:
</p>

<pre>
&lt;first_line&gt; .=. &lt;Number of queries:integer&gt;
&lt;line&gt; .=. &lt;query id: integer&gt; &lt;query length: integer&gt; &lt;query: text&gt;
</pre>

<p>Feature file should be in the following format</p>

<pre>
&lt;Number of query-dependent features&gt;
&lt;Feature descriptions&gt;
&lt;Number of query-independent features&gt;
&lt;Path to feature files&gt;
</pre>

<p>
For a list of supported query-dependent features, please
see <code>sample/features</code>. Query-independent scores
should be stored in a binary file as a sequence of float values,
starting with the score for the first document.
</p>

<a id="Publications"></a>
<p class="lead" style="padding-top: 60px">Publications</p>

<p>Nima Asadi and Jimmy Lin.
  Fast Candidate Generation for Real-Time Tweet Search with Bloom Filter Chains.
  <i>ACM Transactions on Information Systems, 2013, in press.</i>
</p>

<p>Nima Asadi and Jimmy Lin.
  Document Vector Representations for Feature Extraction in Multi-Stage Document Ranking.
  <i>Information Retrieval, 2012, in press.</i>

<p>Nima Asadi, Jimmy Lin, and Arjen P. de Vries.
  Runtime Optimizations for Tree-Based Machine Learning Models.
  <i>IEEE Transactions on Knowledge and Data Engineering, 2013, in press</i>.
</p>

<p>Nima Asadi and Jimmy Lin.
  Effectiveness-Efficiency Tradeoffs for Candidate Generation in Multi-Stage Retrieval Architectures.
  Proceedings of the 36th Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval (SIGIR 2013), Dublin, Ireland.
</p>

</section>
    <footer>
      <p><small>Hosted on GitHub Pages &mdash; Theme based on
          <a href="https://github.com/orderedlist">orderedlist</a></small></p>
    </footer>
    </div>
    <script src="js/scale.fix.js"></script>

  </body>
</html>

