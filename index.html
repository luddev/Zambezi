<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Zambezi</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Zambezi</h1>
        <p>A multi-stage, in-memory search engine for streaming documents</p>

        <p class="view"><a href="http://github.com/nasadi/Zambezi">View the Project on GitHub
            <small>nasadi/Zambezi</small></a></p>
      </header>
      <section>

<h2>Features</h2>

<ul>

  <li><i>multi-stage ranking</i>: search is broken into candidate
  generation, feature extraction, and document reranking (with
  machine-learned models).</li>

  <li><i>in-memory</i>: all index structures are kept in main
  memory.</li>

  <Li><i>streaming documents</i>: designed to incrementally index
  documents as they arrive.</li>

</ul>


<h2>Key Components</h2>

<p><b>In-memory, incremental indexer:</b> An incremental indexing algorithm that constructs
block-compressed positional and non-positional inverted indexes
in the main memory, thereby enabling fast indexing and retrieval.
The indexer is also capable of building Bloom filter chains
to be used with our BW<font size=1>AND</font> algorithm for faster top <i>k</i> retrieval.

<p><b>Candidate generation:</b> As the first stage of retrieval,
Zambezi retrieves top <i>k</i> documents that are most relevant to
an input query. Zambezi uses W<font size=1>AND</font> to retrieve
documents ranked using BM25. For microblog documents, Zambezi utilizes
the BW<font size=1>AND</font> algorithm to retrieve documents
using time and a simplified BM25 scoring function, which is an order
of magnitude faster than W<font size=1>AND</font>.

<p><b>Feature Extraction:</b> Once the top <i>k</i> documents are
retrieved, Zambezi computes feature values for each candidate document
before passing the feature vectors to the final, reranking stage.
Features can be query dependent (e.g., term and phrase queries),
or query independent, given as a table.

<p><b>Document Reranking:</b> In the final stage of retrieval,
candidates are reranked using a machine-learned model.
Currently Zambezi supports Lambda-MART models and evaluates
instances using the VP<font size=1>RED</font> implementation
of trees.

<h2>Quick Demo</h2>
<p>
  As a quick demo, we index the CACM collection (providedunder <code>sample/</code>)
  and retrieve top 1000 documentsper query, using the W<font size=1>AND</font>
  algorithm with BM25 scoring model. To do so, wefirst index thecollection as
follows:</p>

<pre>
out/driver/indexer -index cacm_index/ -mb 1 -tf
                   -input sample/cacm-collection.gz
</pre>

<p>Now, let's perform retrieval:</p>

<pre>
out/driver/retrieval -index cacm_index/ -query sample/cacm-queries.txt
                     -algorithm WAND -hits 1000
                     -docnoMapping sample/cacm-docno-mapping.txt
                     -output wand.output
</pre>

<p>
You can evaluate the ranked list (stored in <code>wand.output</code>) using
the trec_eval script from TREC. Evaluation results should match
<code>sample/cacm-wand.trec_eval.txt</code>.
</p>



<h2>Indexing Guide</h2>

<p>
The input to the index is a set of (gzipped or raw) text files.
Each line in an input file contains one document in the following format:
</p>

<pre>
&lt;document_id: integer&gt; \t &lt;document: text&gt;
</pre>

<p>Please note that, you must perform necessary preprocessing (e.g.,
parsing, stopping, stemming) prior to using the indexer, as the
indexer is only able to read parsed documents and does not perform
any sort of stopping or stemming. We have provided parsers for
ClueWeb09, Gov2, and Tweets2011 collections under <code>util/</code>.
Note that, building these classes requires
<a href="http://lintool.github.com/Cloud9">Cloud<sup>9</sup></a>,
<a href="http://lintool.github.com/Ivory">Ivory</a>,
and <a href="http://twittertools.cc/">twitter-tools</a>.

</p>

<p>
To run the indexer:
</p>

<pre>
out/driver/indexer -index &lt;output-index-root-path&gt; \
  [-tf | -positional] [-reverse] [-vectors] \
  [-bloom -r &lt;bits-per-element&gt; -k &lt;number-of-hash-functions&gt;] \
  -mb &lt;maximum-buffer-length-in-number-of-blocks&gt; \
  -input &lt;input-paths&gt;
</pre>

<p>
<ul>
  <li><code>-index</code> is the root path to where the index should be stored</li>
  <li><code>-tf | -positional</code> determines whether to augment the index structure with
    term frequencies, or term frequencies and term positionsl.</li>
  <li><code>-reverse</code> indicates that postings will be stored in
    reverse order, such that the last posting inserted into the index will be read first.</li>
  <li>With <code>-vectors</code>, the indexer accumulates document vectors which can be used
    in feature extraction.</li>
  <li>With <code>-bloom</code>, the indexer constructs Bloom filter chains to be used with the
    BW<font size=1>AND</font> algorithm in top <i>k</i> retrieval. <code>-r</code> and
    <code>-k</code> are the number of bits per element and the number of hash functions,
    respectively.</li>
  <li><code>-mb</code> is the maximum buffer length (in blocks of 128 integers) in buffer maps.
    Larger values translate into more contiguous inverted lists. Experimental evaluation
    shows that setting <code>-mb</code> to 32 yields retrieval speed that is indistinguishable
    from a fully contiguous index.</li>
  <li><code>-input</code> is a list of (gzipped) input files. Note that, this argument
    must appear last.</li>
</ul>
</p>

<h2>Retrieval Guide</h2>

<p>
To perform retrieval:
</p>

<pre>
out/driver/retrieval -index &lt;index-root-path&gt; \
                     -query &lt;query-path&gt; \
                     -algorithm &lt;SvS|WAND|MBWAND|BWAND_OR|BWAND_AND&gt; \
                     [-features &lt;feature-path&gt;] \
                     [-model &lt;tree-ensemble-path&gt;] \
                     [-hits &lt;hits&gt;] \
                     [-output &lt;output-path&gt; -docnoMapping &lt;mapping-file&gt;]
</pre>

<p>
<ul>
  <li><code>-index</code> is the root path to where the index is stored</li>
  <li><code>-query</code> is the path to a query file</li>
  <li><code>-algorithm</code> is the algorithm used in the top <i>k</i> retrieval
    stage. These algorithms are as follows:</li>
  <ul>
    <li><code>SvS</code>: The Small vs. Small algorithm for conjunctive retrieval.</li>
    <li><code>WAND</code>: The W<font size=1>AND</font> algorithm, using Okapi-BM25 scoring function.</li>
    <li><code>MBWAND</code>: The W<font size=1>AND</font> algorithm, using IDF scoring function</li>
    <li><code>BWAND_OR</code>: The BW<font size=1>AND</font> algorithm in disjunctive mode</li>
    <li><code>BWAND_AND</code>: The BW<font size=1>AND</font> algorithm in conjunctive mode</li>
  </ul>
  <li>With <code>-features</code>, the driver will forward the candidate documents
    to the feature extraction stage and compute feature values</li>
  <li><code>-model</code>, is the path to a file that contains a Lambda-MART model.
    If a model is provided and <code>-features</code> is included,
    candidate documents are reranked using the given model.
    For formatting details of the tree model file,
    please see our open-source tree implementation package,
    <a href="http://nasadi.github.com/OptTrees">OptTrees</a>.</li>
  <li><code>-hits</code> is the number of candidate documents to retrieve (i.e., <i>k</i>).</li>
  <li>If <code>-output</code> is included, the output is stored at &lt;output-path&gt;</li>
  <li>If <code>-docnoMapping</code> is given, document numbers will be replaced with
    document ids in the output file. The docno-mapping file is a text file that contains
    document ids in order (i.e., docid for document 1, docid for document 2, and so on).</li>
</ul>

In all cases, per-query latency is printed on stdout.
</p>

<h3>Queries</h3>
<p>
Also note that, queries should be in the following format:
</p>

<pre>
&lt;first_line&gt; .=. &lt;Number of queries:integer&gt;
&lt;line&gt; .=. &lt;query id: integer&gt; &lt;query length: integer&gt; &lt;query: text&gt;
</pre>

<h3>Features</h3>
<p>Feature file should be in the following format</p>

<pre>
&lt;Number of query-dependent features&gt;
&lt;Feature descriptions&gt;
&lt;Number of query-independent features&gt;
&lt;Path to feature files&gt;
</pre>

<p>
For a list of supported query-dependent features, please
see <code>sample/features</code>. Query-independent scores
should be stored in a binary file as a sequence of float values,
starting with the score for the first document.
</p>

<h3>Output</h3>
<p>
If the algorithm is set to W<font size=1>AND</font> and BW<font size=1>AND</font>_OR,
or a Lambda-MART model is given to re-rank documents, the output is in the TREC evaluation
format.
</p>

<p>
On the other hand, if <code>-features</code> is included but a Lambda-MART model
is not specified, then the output contains a feature vector per candidate document,
where each line of the output is in the following format:
</p>

<pre>
qid docno/docid 1:value-of-feature-1 2:value-of-feature-2 ...
</pre>


<h2>Publications</h2>

<p>Nima Asadi and Jimmy Lin.
  <b>Document Vector Representations for Feature Extraction in Multi-Stage Document Ranking.</b>
  <i>Information Retrieval, 2012, in press.</i>

<p>Nima Asadi and Jimmy Lin.
  <b>Fast Candidate Generation for Real-Time Tweet Search with Bloom Filter Chains.</b>
  <i>ACM Transactions on Information Systems, 2013, in press.</i>
</p>

<p>Nima Asadi, Jimmy Lin, and Arjen P. de Vries.
  <b>Runtime Optimizations for Tree-Based Machine Learning Models.</b>
  <i>IEEE Transactions on Knowledge and Data Engineering, 2013, in press</i>.
</p>

<p>Nima Asadi and Jimmy Lin.
  <b>Effectiveness-Efficiency Tradeoffs for Candidate Generation in Multi-Stage Retrieval Architectures.</b>
  Proceedings of the 36th Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval (SIGIR 2013), Dublin, Ireland.
</p>


<h2>Acknowledgments</h2>

<p>This work has been supported by the US NSF under awards
IIS-0916043, IIS-1144034, and IIS-1218043. Any opinions, findings, or
conclusions are the authors' and do not necessarily reflect those of
the sponsors.</p>

</section>
    <footer>
      <p><small>Theme based on <a href="https://github.com/orderedlist">orderedlist</a></small></p>
    </footer>
    </div>
    <script src="js/scale.fix.js"></script>

  </body>
</html>

